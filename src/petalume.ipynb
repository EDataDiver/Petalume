{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":7021927,"sourceType":"datasetVersion","datasetId":4037960}],"dockerImageVersionId":30558,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from pathlib import Path\nfrom learntools.time_series.style import *  # plot style settings\nfrom learntools.time_series.utils import plot_periodogram, seasonal_plot\nfrom scipy.signal import periodogram\nimport seaborn as sns\nfrom sklearn.linear_model import LinearRegression\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nfrom statsmodels.tsa.deterministic import CalendarFourier, DeterministicProcess\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-11-30T22:46:14.749367Z","iopub.execute_input":"2023-11-30T22:46:14.749869Z","iopub.status.idle":"2023-11-30T22:46:16.761026Z","shell.execute_reply.started":"2023-11-30T22:46:14.749832Z","shell.execute_reply":"2023-11-30T22:46:16.759691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"whole = pd.read_csv(('/kaggle/input/petal3/petal.csv'), parse_dates=[\"Date\"])\n# add train and test files later\n\nprint(whole['Date'].dtypes)# confirm the dates are set up as datetime","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:09:27.160322Z","iopub.execute_input":"2023-11-30T23:09:27.160894Z","iopub.status.idle":"2023-11-30T23:09:30.146622Z","shell.execute_reply.started":"2023-11-30T23:09:27.160855Z","shell.execute_reply":"2023-11-30T23:09:30.145599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Begin Data Exploration**\nTake a look at the data, columns names, data types.\nStart by making a periodogram to see if there are seasonal and other features with periodic frequency to the time series.","metadata":{}},{"cell_type":"code","source":"whole.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:09:30.148179Z","iopub.execute_input":"2023-11-30T23:09:30.149208Z","iopub.status.idle":"2023-11-30T23:09:30.167865Z","shell.execute_reply.started":"2023-11-30T23:09:30.149175Z","shell.execute_reply":"2023-11-30T23:09:30.166823Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"whole.rename(columns={'Est. Gross Profit (Line)': 'Sales'}, inplace=True)\nwhole.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:12.109129Z","iopub.execute_input":"2023-11-30T23:10:12.109625Z","iopub.status.idle":"2023-11-30T23:10:12.130855Z","shell.execute_reply.started":"2023-11-30T23:10:12.109589Z","shell.execute_reply":"2023-11-30T23:10:12.129691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(len(whole))\nwhole.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:12.975914Z","iopub.execute_input":"2023-11-30T23:10:12.976393Z","iopub.status.idle":"2023-11-30T23:10:13.632898Z","shell.execute_reply.started":"2023-11-30T23:10:12.976356Z","shell.execute_reply":"2023-11-30T23:10:13.631522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"whole_sales=whole.groupby('Date')['Sales'].sum() \n\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"365D\") / pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots(figsize=(12, 5))\n     \n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\"Annual (1)\",\"Semiannual (2)\",\"Quarterly (4)\",\"Bimonthly (6)\",\"Monthly (12)\",\"Biweekly (26)\",\"Weekly (52)\",\"Semiweekly (104)\",],rotation=30,)\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram\")\n    return ax\n\nplot_periodogram(whole_sales)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:13.634819Z","iopub.execute_input":"2023-11-30T23:10:13.635178Z","iopub.status.idle":"2023-11-30T23:10:14.654194Z","shell.execute_reply.started":"2023-11-30T23:10:13.635148Z","shell.execute_reply":"2023-11-30T23:10:14.653035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The periodogram looks unusual. The annual peaks very high and wide and other peaks are jagged and indistinct. This could be due to inconsisent sales over time.","metadata":{}},{"cell_type":"code","source":"\nwhole_sales = whole_sales.reset_index()\nwhole_sales.columns = ['Date', 'Sales']\n\nwhole_sales['Date'] = pd.to_datetime(whole_sales['Date'])\n\n\nwhole_sales.sort_values('Date', inplace=True)\n\n\nplt.figure(figsize=(10, 5))  # Set the size of the plot\nplt.plot(whole_sales['Date'], whole_sales['Sales'], marker='o')  # Plot with markers\n\n\nplt.title('Sales Over Time')\nplt.xlabel('Date')\nplt.ylabel('Sales')\n\n\nplt.gcf().autofmt_xdate()\n\nplt.show()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:14.656254Z","iopub.execute_input":"2023-11-30T23:10:14.656643Z","iopub.status.idle":"2023-11-30T23:10:15.235434Z","shell.execute_reply.started":"2023-11-30T23:10:14.656612Z","shell.execute_reply":"2023-11-30T23:10:15.234460Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here we can see that sales from mid-2016-2017 are much higher than the rest of the dataset. These high sales in 2016 will not be helful in predicting the sale behavior in the rest of the dataset. Additionally, there is an evident gap in sales in 2017. Take a closer look at the sales over time starting in 2018.","metadata":{}},{"cell_type":"code","source":"#find the end date for the dataset\nwhole_sales.tail()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:15.238170Z","iopub.execute_input":"2023-11-30T23:10:15.239086Z","iopub.status.idle":"2023-11-30T23:10:15.258586Z","shell.execute_reply.started":"2023-11-30T23:10:15.239033Z","shell.execute_reply":"2023-11-30T23:10:15.256387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#limit the whole_sales dataset to dates starting in 2018 \nwhole_sales.set_index('Date', inplace=True)\nwhole_sales.sort_index(inplace=True)\n\n# Slice the DataFrame to the desired date range\ntruncated_whole_sales = whole_sales.loc['2018-01-01':'2020-08-10']\n#reset and resort the index for graphing \ntruncated_whole_sales = truncated_whole_sales.reset_index()\nwhole_sales.sort_values('Date', inplace=True)\n\nplt.figure(figsize=(10, 5)) \nplt.plot(truncated_whole_sales['Date'], truncated_whole_sales['Sales'], marker='o')  # Plot with markers\n\n\nplt.title('Sales Over Time')\nplt.xlabel('Date')\nplt.ylabel('Sales')\n\nplt.gcf().autofmt_xdate()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:15.260389Z","iopub.execute_input":"2023-11-30T23:10:15.261021Z","iopub.status.idle":"2023-11-30T23:10:15.904646Z","shell.execute_reply.started":"2023-11-30T23:10:15.260971Z","shell.execute_reply":"2023-11-30T23:10:15.903251Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This looks much better. It would be ideal to close in on the sections where there are no gaps. Closing into mid-April 2018 and ending with the expected sales pause on March 17, 2020.","metadata":{}},{"cell_type":"code","source":"truncated_whole_sales = whole_sales.loc['2018-04-15':'2020-03-17']\n#reset and resort the index for graphing \ntruncated_whole_sales = truncated_whole_sales.reset_index()\n#whole_sales.sort_values('Date', inplace=True)\n\nplt.figure(figsize=(10, 5))  # Set the size of the plot\nplt.plot(truncated_whole_sales['Date'], truncated_whole_sales['Sales'], marker='o')  # Plot with markers\n\nplt.title('Sales Over Time')\nplt.xlabel('Date')\nplt.ylabel('Sales')\n\nplt.gcf().autofmt_xdate()\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:15.906330Z","iopub.execute_input":"2023-11-30T23:10:15.907646Z","iopub.status.idle":"2023-11-30T23:10:16.520033Z","shell.execute_reply.started":"2023-11-30T23:10:15.907598Z","shell.execute_reply":"2023-11-30T23:10:16.518577Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"truncated_whole_sales.head(10) # starting sales with 04-26-2018","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:16.521653Z","iopub.execute_input":"2023-11-30T23:10:16.523063Z","iopub.status.idle":"2023-11-30T23:10:16.538030Z","shell.execute_reply.started":"2023-11-30T23:10:16.523016Z","shell.execute_reply":"2023-11-30T23:10:16.536796Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"truncated_whole_sales = whole_sales.loc['2018-04-15':'2020-03-17']\n#reset and resort the index for graphing \ntruncated_whole_sales = truncated_whole_sales.reset_index()\n\ntruncated_whole_sales.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:16.539717Z","iopub.execute_input":"2023-11-30T23:10:16.540191Z","iopub.status.idle":"2023-11-30T23:10:16.557755Z","shell.execute_reply.started":"2023-11-30T23:10:16.540159Z","shell.execute_reply":"2023-11-30T23:10:16.556511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Revisiting Periodogram\ntruncated_whole_sales=truncated_whole_sales.groupby('Date')['Sales'].sum()\n\ndef plot_periodogram(ts, detrend='linear', ax=None):\n    from scipy.signal import periodogram\n    fs = pd.Timedelta(\"365D\") / pd.Timedelta(\"1D\")\n    freqencies, spectrum = periodogram(\n        ts,\n        fs=fs,\n        detrend=detrend,\n        window=\"boxcar\",\n        scaling='spectrum',\n    )\n    if ax is None:\n        _, ax = plt.subplots(figsize=(12, 5))\n     \n    ax.step(freqencies, spectrum, color=\"purple\")\n    ax.set_xscale(\"log\")\n    ax.set_xticks([1, 2, 4, 6, 12, 26, 52, 104])\n    ax.set_xticklabels(\n        [\"Annual (1)\",\"Semiannual (2)\",\"Quarterly (4)\",\"Bimonthly (6)\",\"Monthly (12)\",\"Biweekly (26)\",\"Weekly (52)\",\"Semiweekly (104)\",],rotation=30,)\n    ax.ticklabel_format(axis=\"y\", style=\"sci\", scilimits=(0, 0))\n    ax.set_ylabel(\"Variance\")\n    ax.set_title(\"Periodogram\")\n    return ax\n\n#plot_periodogram(aggsale_train)\n\nplot_periodogram(truncated_whole_sales)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:16.562060Z","iopub.execute_input":"2023-11-30T23:10:16.562482Z","iopub.status.idle":"2023-11-30T23:10:17.502273Z","shell.execute_reply.started":"2023-11-30T23:10:16.562435Z","shell.execute_reply":"2023-11-30T23:10:17.501155Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"This is more similar to an expected periodogram. There seems to be a weekly component to sales, as well as monthly, bimonthly, quarterly, semiannually and annual patterns.\nThe next step is to create a model to capture these features, take a look at the model fit, and then use the model's prediction to confirm the periodogram is deseasoned when these features are implemented.\nThe first step here will be to split the model into a training set and a test set, such that time series predictions can be verified. For these purposes, 15 days of predicition should be sufficient.\n","metadata":{}},{"cell_type":"code","source":"whole.dtypes","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:17.504011Z","iopub.execute_input":"2023-11-30T23:10:17.504645Z","iopub.status.idle":"2023-11-30T23:10:17.514602Z","shell.execute_reply.started":"2023-11-30T23:10:17.504610Z","shell.execute_reply":"2023-11-30T23:10:17.513022Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Count the number of 0.0 values in a specific column\nnumber_of_zeros = (whole['Quantity'] == 0.0).sum()\nprint(f\"Number of 0.0 values in column '{'Quantity'}': {number_of_zeros}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:17.516472Z","iopub.execute_input":"2023-11-30T23:10:17.516856Z","iopub.status.idle":"2023-11-30T23:10:17.528446Z","shell.execute_reply.started":"2023-11-30T23:10:17.516824Z","shell.execute_reply":"2023-11-30T23:10:17.526773Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"whole.set_index('Date', inplace=True)\n#sort by the index\nwhole.sort_index(inplace=True)\n#slice to set up train and test\n\ntrain= whole.loc['2018-04-26':'2020-03-02']\ntest= whole.loc['2020-03-03':'2020-03-17']\n\naggsale_train = train['Sales'].groupby(train.index).sum()\naggsale_test = test['Sales'].groupby(test.index).sum()\n\naggsale_train.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:17.529896Z","iopub.execute_input":"2023-11-30T23:10:17.530242Z","iopub.status.idle":"2023-11-30T23:10:17.580226Z","shell.execute_reply.started":"2023-11-30T23:10:17.530214Z","shell.execute_reply":"2023-11-30T23:10:17.578985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"First convert the dates to periods with a frequency of daily for use in the model","metadata":{}},{"cell_type":"code","source":"aggsale_train = aggsale_train.asfreq('D')\nprint(aggsale_train.index.freq)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:17.581999Z","iopub.execute_input":"2023-11-30T23:10:17.582752Z","iopub.status.idle":"2023-11-30T23:10:17.591450Z","shell.execute_reply.started":"2023-11-30T23:10:17.582689Z","shell.execute_reply":"2023-11-30T23:10:17.590197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(aggsale_train.isna().sum())","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:17.594682Z","iopub.execute_input":"2023-11-30T23:10:17.595864Z","iopub.status.idle":"2023-11-30T23:10:17.604356Z","shell.execute_reply.started":"2023-11-30T23:10:17.595828Z","shell.execute_reply":"2023-11-30T23:10:17.603141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"There are 19 dates added to the time series that were previously missing. Take look to see if there is a pattern to missing dates.","metadata":{}},{"cell_type":"code","source":"aggsale_train = aggsale_train.reset_index()\naggsale_train.columns = ['Date', 'Sales']\n\nnan_dates = aggsale_train[aggsale_train['Sales'].isna()]['Date']\nprint(nan_dates)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:17.606096Z","iopub.execute_input":"2023-11-30T23:10:17.606979Z","iopub.status.idle":"2023-11-30T23:10:17.618749Z","shell.execute_reply.started":"2023-11-30T23:10:17.606943Z","shell.execute_reply":"2023-11-30T23:10:17.617474Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Some of these dates align with holiday store closures, Such as 12-25, 07-04. Others may relate to store closures near Thanksgiving and Labor Day. The best way to deal with these nan (no entry in the sales column) is to convert them to 0's, indicating no sales.","metadata":{}},{"cell_type":"code","source":"aggsale_train['Sales'].fillna(0, inplace = True)\naggsale_train.isna().sum()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:17.742963Z","iopub.execute_input":"2023-11-30T23:10:17.743421Z","iopub.status.idle":"2023-11-30T23:10:17.753644Z","shell.execute_reply.started":"2023-11-30T23:10:17.743386Z","shell.execute_reply":"2023-11-30T23:10:17.752635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Convert dataframe back to periodic frequency\naggsale_train.set_index('Date', inplace=True)\naggsale_train = aggsale_train.asfreq('D')\nprint(aggsale_train.index.freq)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:18.062056Z","iopub.execute_input":"2023-11-30T23:10:18.063308Z","iopub.status.idle":"2023-11-30T23:10:18.072546Z","shell.execute_reply.started":"2023-11-30T23:10:18.063264Z","shell.execute_reply":"2023-11-30T23:10:18.071051Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create a model\ny = aggsale_train.copy()\nfourier = CalendarFourier(freq='M', order=4)\nfourier_annual = CalendarFourier(freq='A', order=4)\nfourier_weekly = CalendarFourier(freq='W', order=4)\nfourier_quarterly = CalendarFourier(freq='Q', order=4)\n# Bimonthly Fourier\nfourier_bimonthly = CalendarFourier(freq='2M', order=4)\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    order=1,\n    seasonal=True,\n    additional_terms=[fourier,fourier_weekly,fourier_annual,fourier_quarterly, fourier_bimonthly],\n    drop=True,\n)\nX = dp.in_sample()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:18.298945Z","iopub.execute_input":"2023-11-30T23:10:18.299409Z","iopub.status.idle":"2023-11-30T23:10:18.388211Z","shell.execute_reply.started":"2023-11-30T23:10:18.299375Z","shell.execute_reply":"2023-11-30T23:10:18.385626Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Run the model\nmodel = LinearRegression().fit(X, y)\ny_pred = pd.Series(\n    model.predict(X)[:, 0], #this flattens by slicing\n    index=X.index,\n    name='Fitted',\n)\n\nax = y.plot(**plot_params, alpha=0.5, title=\"Average Sales\", ylabel=\"items sold\")\nax = y_pred.plot(ax=ax, label=\"Seasonal\")\nax.legend();","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:18.558873Z","iopub.execute_input":"2023-11-30T23:10:18.559344Z","iopub.status.idle":"2023-11-30T23:10:19.292087Z","shell.execute_reply.started":"2023-11-30T23:10:18.559308Z","shell.execute_reply":"2023-11-30T23:10:19.290619Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Root Mean Squared Logrithmin Error (RSMLE) is a method of measuring the error in the curve generated in the model compared to original samples. \n","metadata":{}},{"cell_type":"code","source":"def rmsle(y_true, y_pred):\n    \n    # Ensure the arrays are numpy arrays\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    \n    # Compute the squared logarithmic error\n    error = (np.log(y_pred + 1) - np.log(y_true + 1)) ** 2\n    \n    # Return the square root of the mean of the squared logarithmic error\n    return np.sqrt(np.mean(error))","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:19.294561Z","iopub.execute_input":"2023-11-30T23:10:19.295052Z","iopub.status.idle":"2023-11-30T23:10:19.303772Z","shell.execute_reply.started":"2023-11-30T23:10:19.295011Z","shell.execute_reply":"2023-11-30T23:10:19.302202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"in_sample_rmsle = rmsle(y, y_pred)\nprint(f\"In-sample RMSLE: {in_sample_rmsle}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:19.327706Z","iopub.execute_input":"2023-11-30T23:10:19.328199Z","iopub.status.idle":"2023-11-30T23:10:19.336420Z","shell.execute_reply.started":"2023-11-30T23:10:19.328162Z","shell.execute_reply":"2023-11-30T23:10:19.335098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"RSMLE values are relative, it will be compared to out-sample (future prediction generated from the test set) as well as further modifications for the model. A lower value is lower error in the model.\nNext, verify that the main features of the periodogram have been captured by the model, by generating a priodogram with the model substrated.","metadata":{}},{"cell_type":"code","source":"y_squ = np.squeeze(y)\nprint(y_squ.shape)\nprint(X.shape)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:19.883536Z","iopub.execute_input":"2023-11-30T23:10:19.884856Z","iopub.status.idle":"2023-11-30T23:10:19.892438Z","shell.execute_reply.started":"2023-11-30T23:10:19.884802Z","shell.execute_reply":"2023-11-30T23:10:19.890929Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#deseason the data and look at the periodogram to see if any more seasonailty not captured\ny_deseason = y_squ - y_pred\n\nfig, (ax1, ax2) = plt.subplots(2, 1, sharex=True, sharey=True, figsize=(10, 7))\nax1 = plot_periodogram(y_squ, ax=ax1)\nax1.set_title(\"Product Sales Frequency Components\")\nax2 = plot_periodogram(y_deseason, ax=ax2);\nax2.set_title(\"Deseasonalized\");\n#it appears that seaonality of the slaes is captured","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:20.204464Z","iopub.execute_input":"2023-11-30T23:10:20.204987Z","iopub.status.idle":"2023-11-30T23:10:22.043966Z","shell.execute_reply.started":"2023-11-30T23:10:20.204948Z","shell.execute_reply":"2023-11-30T23:10:22.042486Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The seasonality of the data looks to be covered in the model. \nNow, exploring additional features to add to the model.\nStarting by taking a look at days of the week, days of the month, sales across weeks, months and years to look for any trends that may not have been captured in the model.","metadata":{}},{"cell_type":"code","source":"aggsale_train = aggsale_train.reset_index()\nprint(aggsale_train.columns)\naggsale_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:22.046424Z","iopub.execute_input":"2023-11-30T23:10:22.046966Z","iopub.status.idle":"2023-11-30T23:10:22.064230Z","shell.execute_reply.started":"2023-11-30T23:10:22.046917Z","shell.execute_reply":"2023-11-30T23:10:22.062842Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nCOLORS = list(sns.color_palette())\ndef plot_date_distribution():   \n    \n    df = aggsale_train.copy().sort_values([\"Date\"], ignore_index=True)\n    df[\"day\"] = df.Date.dt.day\n    df[\"month\"] = df.Date.dt.month\n    df[\"year\"] = df.Date.dt.year\n    df[\"day_of_week\"] = df.Date.dt.dayofweek\n    df[\"day_of_year\"] = df.Date.dt.dayofyear\n    df[\"week_of_year\"] = df.Date.dt.isocalendar().week.astype(int)\n    df[\"date_index\"] = df.Date.factorize()[0]\n    plot_kwargs = {\n        \"linewidth\": 2,\n        \"flierprops\": {\"alpha\": 0.2},\n        \"orient\": \"h\",}\n    \n    fig = plt.figure(figsize=(18, 24))\n    gs = fig.add_gridspec(5, 2, height_ratios=(3, 5, 2, 5, 5))\n    sns.boxplot(\n        data=df,\n        y=\"day_of_week\",\n        x=\"Sales\",\n        color=COLORS[0],\n        ax=fig.add_subplot(gs[0, 0]),\n        **plot_kwargs,\n    )\n    plt.title(\"Distribution of Sales across the Days of the Week\")\n    \n    sns.boxplot(\n        data=df,\n        y=\"month\",\n        x=\"Sales\",\n        color=COLORS[1],\n        ax=fig.add_subplot(gs[1, 0]),\n        **plot_kwargs,\n         )\n    plt.title(\"Distribution of Sales across the Months\")\n    \n    sns.boxplot(\n        data=df,\n        y=\"year\",\n        x=\"Sales\",\n        color=COLORS[2],\n        ax=fig.add_subplot(gs[2, 0]),\n        **plot_kwargs,\n    )\n    plt.title(\"Distribution of Sales across the Years\")\n    \n    sns.boxplot(\n        data=df,\n        y=\"day\",\n        x=\"Sales\",\n        color=COLORS[3],\n                ax=fig.add_subplot(gs[:3, 1]),\n        **plot_kwargs,\n    )\n    plt.title(\"Distribution of Sales across the Days of the Month\")\n    sns.lineplot(\n        data=df.groupby(\"day_of_year\").Sales.mean().reset_index(),\n        x=\"day_of_year\",\n        y=\"Sales\",\n        color=COLORS[4],\n        ax=fig.add_subplot(gs[3, 0]),\n        linewidth=2,\n    )\n    plt.ylabel(\"Average Sales\")\n    plt.title(\"Average Sales across the Days of the Year\")\n    \n    sns.lineplot(\n        data=df.groupby(\"week_of_year\").Sales.mean().reset_index(),\n        x=\"week_of_year\",\n        y=\"Sales\",\n        color=COLORS[5],\n        ax=fig.add_subplot(gs[3, 1]),\n        linewidth=2,\n    )\n    plt.ylabel(\"Average Sales\")\n    plt.title(\"Average Sales across the Weeks of the Year\")\n        \n    sns.lineplot(\n        data=df.groupby(\"date_index\").Sales.mean().reset_index(),\n        x=\"date_index\",\n        y=\"Sales\",\n        color=COLORS[6],\n        ax=fig.add_subplot(gs[4, :]),\n        linewidth=2,\n    )\n    plt.ylabel(\"Average Sales\")\n    plt.title(\"Average Sales across the Date Index\")\n    \n    plt.tight_layout()\n    plt.show()\n    \nplot_date_distribution()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:29.470363Z","iopub.execute_input":"2023-11-30T23:10:29.470850Z","iopub.status.idle":"2023-11-30T23:10:32.352399Z","shell.execute_reply.started":"2023-11-30T23:10:29.470812Z","shell.execute_reply":"2023-11-30T23:10:32.350996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The sales are higher on Saturdays, and then Sundays and Mondays. The day of the week feature should already covered by the weekly feature in the model (this was confirmed separately and addition of a day of the week feature did not affect the model, so was omitted). There is no particular trend apparent in the day of the month or yearly graphs. Sales are highest Nov-Dec, as expected, and this is likely covered with the annual feature in the model.\n\nMoving forward, adding in specific holidays that repeat annually, adding in days with 0 sales (store closed) as a feature, and then investigating features exploring sales categories, brands and products.","metadata":{}},{"cell_type":"code","source":"y_deseason = y_squ - y_pred\naverage_sales_value = y_deseason.median() \nholiday_deviations = abs(y_deseason[aggsale_train.index] - average_sales_value)\nimpactful_holidays = holiday_deviations.sort_values(ascending=False)\nimpactful_holidays.head() \n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:32.354693Z","iopub.execute_input":"2023-11-30T23:10:32.355129Z","iopub.status.idle":"2023-11-30T23:10:32.370285Z","shell.execute_reply.started":"2023-11-30T23:10:32.355095Z","shell.execute_reply":"2023-11-30T23:10:32.368441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"impactful_holidays = impactful_holidays.reset_index()\nprint(impactful_holidays.columns)\nimpactful_holidays.head(20)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:32.371981Z","iopub.execute_input":"2023-11-30T23:10:32.372349Z","iopub.status.idle":"2023-11-30T23:10:32.388986Z","shell.execute_reply.started":"2023-11-30T23:10:32.372317Z","shell.execute_reply":"2023-11-30T23:10:32.387653Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n#Create a 'month_day' column to hold the month and day\nimpactful_holidays['month_day'] = impactful_holidays['Date'].dt.strftime('%m-%d')\n\n# Sort the dataframe by 'month_day' and the impact scores in descending order\nimpactful_holidays_sorted = impactful_holidays.sort_values(by=['month_day', 0], ascending=[True, False])\n\n\n# This function will check if there are high impact scores on the same 'month_day' across different years\ndef filter_high_impact_days(group):\n    if group['Date'].dt.year.nunique() > 1:  # Checking if there are entries from multiple years\n        return group\n\n# Apply the filter function to each group\nhigh_impact_dates = impactful_holidays_sorted.groupby('month_day').apply(filter_high_impact_days)\n\n# If you want to reset the index to get a clean dataframe\nhigh_impact_dates.reset_index(drop=True, inplace=True)\n\nprint(high_impact_dates)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:32.391680Z","iopub.execute_input":"2023-11-30T23:10:32.392177Z","iopub.status.idle":"2023-11-30T23:10:33.120065Z","shell.execute_reply.started":"2023-11-30T23:10:32.392135Z","shell.execute_reply":"2023-11-30T23:10:33.118801Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Group by 'month_day' and get the maximum impact score for each group\nmax_impact_scores = high_impact_dates.groupby('month_day')[0].max().reset_index()\n\n# Sort the result by the impact score in descending order to have the highest impacts at the top\nmax_impact_scores_sorted = max_impact_scores.sort_values(by=0, ascending=False).reset_index(drop=True)\n\n# Now max_impact_scores_sorted will have the highest impact score for each month-day, sorted from highest to lowest\nmax_impact_scores_sorted.head(30)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:33.121925Z","iopub.execute_input":"2023-11-30T23:10:33.122375Z","iopub.status.idle":"2023-11-30T23:10:33.145491Z","shell.execute_reply.started":"2023-11-30T23:10:33.122333Z","shell.execute_reply":"2023-11-30T23:10:33.143934Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#it looks like there are high impact sales in the days leading up to Christmas, determine which days to use\nstart_date = '12-14'\nend_date = '12-25'\n\n# Filter the DataFrame based on the date range\nfiltered_df = max_impact_scores_sorted[(max_impact_scores_sorted['month_day'] >= start_date) & (max_impact_scores_sorted['month_day'] <= end_date)]\n\nprint(filtered_df)\n# sorting through excel reveals that the average impact is highest 12-21 thru 12-25 both yea","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:33.147410Z","iopub.execute_input":"2023-11-30T23:10:33.147999Z","iopub.status.idle":"2023-11-30T23:10:33.159604Z","shell.execute_reply.started":"2023-11-30T23:10:33.147957Z","shell.execute_reply":"2023-11-30T23:10:33.157971Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggsale_train['Date'].dtypes","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:33.161179Z","iopub.execute_input":"2023-11-30T23:10:33.161563Z","iopub.status.idle":"2023-11-30T23:10:33.174707Z","shell.execute_reply.started":"2023-11-30T23:10:33.161532Z","shell.execute_reply":"2023-11-30T23:10:33.173487Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# take a look to confirm that sales where far above or below median on particular dates as indicated above\n\nparticular_date = '2019-12-18'\n\n# Convert the string to a datetime object\nparticular_date = pd.to_datetime(particular_date)\n\n# Use loc to filter the dataframe for the particular date\nsales_on_particular_date = aggsale_train.loc[aggsale_train['Date'] == particular_date]\n\nprint(sales_on_particular_date)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:33.176982Z","iopub.execute_input":"2023-11-30T23:10:33.177463Z","iopub.status.idle":"2023-11-30T23:10:33.190985Z","shell.execute_reply.started":"2023-11-30T23:10:33.177432Z","shell.execute_reply":"2023-11-30T23:10:33.189552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"It looks like December 20-25 could have an impact on the model. Additionally, December 18 and 14 could have an impact. \nThe model will be run with and without these additional dates to see the impact on the RSMLE, but first, more features.  ","metadata":{}},{"cell_type":"code","source":"#new column called store closed that has a 1 when sales = 0  \naggsale_train['Store_closed'] = (aggsale_train['Sales'] == 0).astype(int)\naggsale_train.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:33.558744Z","iopub.execute_input":"2023-11-30T23:10:33.559555Z","iopub.status.idle":"2023-11-30T23:10:33.574186Z","shell.execute_reply.started":"2023-11-30T23:10:33.559515Z","shell.execute_reply":"2023-11-30T23:10:33.572710Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# now, do the same for aggsale_test, convert to dataframe first\naggsale_test = aggsale_test.reset_index()\n#print(aggsale_test.columns)\naggsale_test['Store_closed'] = (aggsale_test['Sales'] == 0).astype(int)\naggsale_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:33.967533Z","iopub.execute_input":"2023-11-30T23:10:33.968005Z","iopub.status.idle":"2023-11-30T23:10:33.983148Z","shell.execute_reply.started":"2023-11-30T23:10:33.967970Z","shell.execute_reply":"2023-11-30T23:10:33.981968Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, exploring features based on Account categories.\ncreate account_type column in train df ( the df filtered for dates from whole, contains all columns), get dummies, then merge with aggsale_train grouped by date with sum or sales and of each account_type column","metadata":{}},{"cell_type":"code","source":"\ntrain_at = train\ntrain_at = train_at.drop(['Item', 'COGS Amount','Est. Unit Cost','Category','Product Line'], axis=1)\ntrain_at.head()\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:34.868440Z","iopub.execute_input":"2023-11-30T23:10:34.871393Z","iopub.status.idle":"2023-11-30T23:10:34.931386Z","shell.execute_reply.started":"2023-11-30T23:10:34.871328Z","shell.execute_reply":"2023-11-30T23:10:34.930172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"conditions = [\n    train_at['Account'].str.contains('Inventory', case=False, na=False),\n    train_at['Account'].str.contains('Cost of Goods', case=False, na=False),\n    train_at['Account'].str.contains('Logistics', case=False, na=False),    \n    train_at['Account'].str.contains('Revenue', case=False, na=False) & train['Account'].str.contains('candles', case=False, na=False),\n    train_at['Account'].str.contains('Revenue', case=False, na=False) & train['Account'].str.contains('Accessories', case=False, na=False),\n    train_at['Account'].str.contains('Workshop', case=False, na=False),\n    ]\n\n# Define the choices corresponding to conditions\nchoices = [\n    'Inventory',\n    'Cost of Goods',\n    'Logistics',\n    'Revenue candles',\n    'Revenue Accessories',\n    'Revenue Workshop',\n    ]\n\n# Create the new column using np.select()\n\ntrain_at['Account_type'] = np.select(conditions, choices, default=np.nan)\n\n\ntrain_at.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:35.275662Z","iopub.execute_input":"2023-11-30T23:10:35.276591Z","iopub.status.idle":"2023-11-30T23:10:45.777637Z","shell.execute_reply.started":"2023-11-30T23:10:35.276546Z","shell.execute_reply":"2023-11-30T23:10:45.776392Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_at = test\nconditions = [\n    test_at['Account'].str.contains('Inventory', case=False, na=False),\n    test_at['Account'].str.contains('Cost of Goods', case=False, na=False),\n    test_at['Account'].str.contains('Logistics', case=False, na=False),    \n    test_at['Account'].str.contains('Revenue', case=False, na=False) & test_at['Account'].str.contains('candles', case=False, na=False),\n    test_at['Account'].str.contains('Revenue', case=False, na=False) & test_at['Account'].str.contains('Accessories', case=False, na=False),\n    test_at['Account'].str.contains('Workshop', case=False, na=False),\n    ]\n\n# Define the choices corresponding to conditions\nchoices = [\n    'Inventory',\n    'Cost of Goods',\n    'Logistics',\n    'Revenue candles',\n    'Revenue Accessories',\n    'Revenue Workshop',\n    \n]\n\n# Create the new column using np.select()\n\ntest_at['Account_type'] = np.select(conditions, choices, default=np.nan)\n\n\ntest_at.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:45.779918Z","iopub.execute_input":"2023-11-30T23:10:45.780292Z","iopub.status.idle":"2023-11-30T23:10:46.094006Z","shell.execute_reply.started":"2023-11-30T23:10:45.780262Z","shell.execute_reply":"2023-11-30T23:10:46.092814Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_at['Account_type'].unique().tolist()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:46.095826Z","iopub.execute_input":"2023-11-30T23:10:46.096561Z","iopub.status.idle":"2023-11-30T23:10:46.191275Z","shell.execute_reply.started":"2023-11-30T23:10:46.096518Z","shell.execute_reply":"2023-11-30T23:10:46.189933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Replace NaN with a placeholder value,'Unknown', then create dummies and concat\ntrain_at['Account_type'] = train_at['Account_type'].fillna('Unknown')\ntest_at['Account_type'] = test_at['Account_type'].fillna('Unknown')\naccount_type_dummies = pd.get_dummies(train_at['Account_type']).astype(int)\naccount_type_dummies_test = pd.get_dummies(test_at['Account_type']).astype(int)\n\n\naccount_type_dummies.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:46.194006Z","iopub.execute_input":"2023-11-30T23:10:46.194417Z","iopub.status.idle":"2023-11-30T23:10:46.489844Z","shell.execute_reply.started":"2023-11-30T23:10:46.194385Z","shell.execute_reply":"2023-11-30T23:10:46.488572Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ntrain_gr = train_at.drop(['Quantity','Account','Description'], axis =1)\ntrain_gr.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:46.491297Z","iopub.execute_input":"2023-11-30T23:10:46.491672Z","iopub.status.idle":"2023-11-30T23:10:46.531179Z","shell.execute_reply.started":"2023-11-30T23:10:46.491642Z","shell.execute_reply":"2023-11-30T23:10:46.529985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nnumber_of_revenue_workshops = (train_gr['Account_type'] == 'Revenue Workshop').sum()\nprint(f\"Number of 'Revenue Workshop' entries: {number_of_revenue_workshops}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:46.532821Z","iopub.execute_input":"2023-11-30T23:10:46.533239Z","iopub.status.idle":"2023-11-30T23:10:46.685473Z","shell.execute_reply.started":"2023-11-30T23:10:46.533206Z","shell.execute_reply":"2023-11-30T23:10:46.684001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef plot_date_distribution(df):\n    \n    df_red = df[(df['Account_type'] != 'Cost of Goods')  & (df['Account_type'] != 'nan')]\n\n    plt.figure(figsize=(9, 5))\n    ax = sns.boxplot(\n        data=df_red,\n        x=\"Sales\",\n        y=\"Account_type\",\n        palette=\"viridis\"\n    )\n    \n    q1 = df_red['Sales'].quantile(0.25)\n    q3 = df_red['Sales'].quantile(0.75)\n    iqr = q3 - q1\n\n    \n    #ax.set_xlim([q1 - 1.5 * iqr, q3 + 1.5 * iqr])\n    ax.set_xlim([0, q3 + 1.5 * iqr])\n\n    plt.title(\"Distribution of Sales by Account Type\")\n    plt.xlabel(\"Sales\")\n    plt.ylabel(\"Account Type\")\n    plt.show()\n\n# Call the function with your data\nplot_date_distribution(train_gr)\n\n\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:46.686867Z","iopub.execute_input":"2023-11-30T23:10:46.687343Z","iopub.status.idle":"2023-11-30T23:10:47.887203Z","shell.execute_reply.started":"2023-11-30T23:10:46.687301Z","shell.execute_reply":"2023-11-30T23:10:47.885811Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Inspect the data for \"Workshops\"\nworkshops_data = train_gr[train_gr['Account_type'] == 'Revenue Workshop']\nprint(workshops_data['Sales'].describe())\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:47.889181Z","iopub.execute_input":"2023-11-30T23:10:47.889682Z","iopub.status.idle":"2023-11-30T23:10:48.044536Z","shell.execute_reply.started":"2023-11-30T23:10:47.889637Z","shell.execute_reply":"2023-11-30T23:10:48.043507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Filter to find the specific rows where 'Account_type' is 'Revenue Workshop' and 'Sales' is 2272\noutliers = train_gr[(train_gr['Account_type'] == 'Revenue Workshop') & (train_gr['Sales'] >= 800)]\n\n# Print the outlier rows to investigate\nprint(outliers)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:48.045654Z","iopub.execute_input":"2023-11-30T23:10:48.046803Z","iopub.status.idle":"2023-11-30T23:10:48.200675Z","shell.execute_reply.started":"2023-11-30T23:10:48.046762Z","shell.execute_reply":"2023-11-30T23:10:48.199827Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Revenue workshops seemed to have high values, but they appear to be legitimate. Try adjusting to log scale to adjust for these high values.","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(8, 4))\nax = sns.boxplot(x='Account_type', y='Sales', data=train_gr, palette='Set2')\n\n# Set the y-axis to a logarithmic scale\nax.set_yscale('log')\n\nplt.xticks([0,1,2,3,4,5,6], [\"Candles\", \"Cost of Goods\", \"Inventory\",'Accessories','Other','Workshops','Logistics'])\nplt.title('Sales Distribution by Account Type')\nplt.xlabel('Account Type')\nplt.ylabel('Sales')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:48.205466Z","iopub.execute_input":"2023-11-30T23:10:48.206505Z","iopub.status.idle":"2023-11-30T23:10:49.813689Z","shell.execute_reply.started":"2023-11-30T23:10:48.206466Z","shell.execute_reply":"2023-11-30T23:10:49.811985Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndf_filtered = train_gr[(train_gr['Account_type'] != 'Cost of Goods') & \n                       (train_gr['Account_type'] != 'Inventory') &\n                       (train_gr['Account_type'] != 'nan') &\n                       (train_gr['Account_type'] != 'Logistics') &\n                       (~pd.isna(train_gr['Account_type']))]\n\n# Now create the plot using df_filtered\nplt.figure(figsize=(8, 5))\nax = sns.boxplot(x='Sales', y='Account_type', data=df_filtered, palette='Set2')\n\n# Set the y-axis to a logarithmic scale\nax.set_xscale('log')\n\nplt.yticks([0,1,2], [\"Candles\", 'Accessories','Workshops'])\nplt.title('Sales Distribution by Account Type')\nplt.xlabel('Sales')\nplt.ylabel('Account Type')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:49.815419Z","iopub.execute_input":"2023-11-30T23:10:49.815949Z","iopub.status.idle":"2023-11-30T23:10:51.541238Z","shell.execute_reply.started":"2023-11-30T23:10:49.815904Z","shell.execute_reply":"2023-11-30T23:10:51.539843Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Aggregate the dummies at a daily level\naccount_dummies_agg = account_type_dummies.groupby('Date').sum() \naccount_dummies_agg_t = account_type_dummies_test.groupby('Date').sum() \n\naccount_dummies_agg.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:51.542845Z","iopub.execute_input":"2023-11-30T23:10:51.543250Z","iopub.status.idle":"2023-11-30T23:10:51.593807Z","shell.execute_reply.started":"2023-11-30T23:10:51.543217Z","shell.execute_reply":"2023-11-30T23:10:51.592344Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"account_dummies_agg = account_dummies_agg.reset_index()\naccount_dummies_agg_t = account_dummies_agg_t.reset_index()\naccount_dummies_agg_t.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:51.595761Z","iopub.execute_input":"2023-11-30T23:10:51.596184Z","iopub.status.idle":"2023-11-30T23:10:51.613802Z","shell.execute_reply.started":"2023-11-30T23:10:51.596150Z","shell.execute_reply":"2023-11-30T23:10:51.612484Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Merge\naggsale_train= aggsale_train.merge(account_dummies_agg, on='Date', how='left')\naggsale_test= aggsale_test.merge(account_dummies_agg_t, on='Date', how='left')\naggsale_train.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:51.615390Z","iopub.execute_input":"2023-11-30T23:10:51.615793Z","iopub.status.idle":"2023-11-30T23:10:51.648420Z","shell.execute_reply.started":"2023-11-30T23:10:51.615748Z","shell.execute_reply":"2023-11-30T23:10:51.647141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Next, adding features for Brands and Product type. There are 135 unique brands in the dataset. In order to see the top ten brands by sales, group the date by brand and sum the sales for each category. ","metadata":{}},{"cell_type":"code","source":"aggsale_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:51.649839Z","iopub.execute_input":"2023-11-30T23:10:51.650739Z","iopub.status.idle":"2023-11-30T23:10:51.668364Z","shell.execute_reply.started":"2023-11-30T23:10:51.650664Z","shell.execute_reply":"2023-11-30T23:10:51.666975Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Brand'].nunique()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:51.669841Z","iopub.execute_input":"2023-11-30T23:10:51.670235Z","iopub.status.idle":"2023-11-30T23:10:51.773361Z","shell.execute_reply.started":"2023-11-30T23:10:51.670203Z","shell.execute_reply":"2023-11-30T23:10:51.771961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brand_sales_sum = train_gr.groupby('Brand')['Sales'].sum()\n\n# Sort the sums in descending order and get the top 10\ntop_ten_brands = brand_sales_sum.sort_values(ascending=False).head(10)\n\n# Print the top 10 brands\nprint(top_ten_brands)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:51.775071Z","iopub.execute_input":"2023-11-30T23:10:51.775638Z","iopub.status.idle":"2023-11-30T23:10:51.975572Z","shell.execute_reply.started":"2023-11-30T23:10:51.775596Z","shell.execute_reply":"2023-11-30T23:10:51.973986Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brand_sales_sumt = test.groupby('Brand')['Sales'].sum()\ntop_ten_brandst = brand_sales_sumt.sort_values(ascending=False).head(10)\n\n\nprint(top_ten_brandst)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:51.977203Z","iopub.execute_input":"2023-11-30T23:10:51.977602Z","iopub.status.idle":"2023-11-30T23:10:51.995568Z","shell.execute_reply.started":"2023-11-30T23:10:51.977568Z","shell.execute_reply":"2023-11-30T23:10:51.993931Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(8, 5))\nsns.barplot(x=top_ten_brands.values, y=top_ten_brands.index)\nplt.title('Top Ten Selling Brands')\nplt.xlabel('Total Sales')\nplt.ylabel('Brand')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:51.997366Z","iopub.execute_input":"2023-11-30T23:10:51.997865Z","iopub.status.idle":"2023-11-30T23:10:52.467765Z","shell.execute_reply.started":"2023-11-30T23:10:51.997822Z","shell.execute_reply":"2023-11-30T23:10:52.466345Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Now, make a feature with the brands that are in common for both the training and test datasets","metadata":{}},{"cell_type":"code","source":"set1 = set(top_ten_brands.index)\nset2 = set(top_ten_brandst.index)\n\ncommon_brands = set1.intersection(set2)\ncommon_brands_list = list(common_brands)\nprint(common_brands_list)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:52.469342Z","iopub.execute_input":"2023-11-30T23:10:52.469762Z","iopub.status.idle":"2023-11-30T23:10:52.477328Z","shell.execute_reply.started":"2023-11-30T23:10:52.469707Z","shell.execute_reply":"2023-11-30T23:10:52.475896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def categorize_brand(brand):\n    if brand in common_brands_list:\n        return brand\n    else:\n        return 'Other'\n\n# Apply the function to the 'Brand' column\ntrain_at['Common_Brand'] = train_at['Brand'].apply(categorize_brand)\ntest_at['Common_Brand'] = test_at['Brand'].apply(categorize_brand)\n\n# Create dummy variables\nbrand_dummies_train = pd.get_dummies(train_at['Common_Brand']).astype(int)\nbrand_dummies_test = pd.get_dummies(test_at['Common_Brand']).astype(int)\n\n# Checking the result\nbrand_dummies_train.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:52.479093Z","iopub.execute_input":"2023-11-30T23:10:52.479529Z","iopub.status.idle":"2023-11-30T23:10:52.967412Z","shell.execute_reply.started":"2023-11-30T23:10:52.479498Z","shell.execute_reply":"2023-11-30T23:10:52.966212Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brand_dummies_train = brand_dummies_train.drop(['Other'], axis =1)\nbrand_dummies_test = brand_dummies_test.drop(['Other'], axis =1)\nbrand_dummies_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:52.969642Z","iopub.execute_input":"2023-11-30T23:10:52.970116Z","iopub.status.idle":"2023-11-30T23:10:53.003641Z","shell.execute_reply.started":"2023-11-30T23:10:52.970080Z","shell.execute_reply":"2023-11-30T23:10:53.001862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brand_dummies_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:53.005927Z","iopub.execute_input":"2023-11-30T23:10:53.007003Z","iopub.status.idle":"2023-11-30T23:10:53.022365Z","shell.execute_reply.started":"2023-11-30T23:10:53.006960Z","shell.execute_reply":"2023-11-30T23:10:53.020771Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#aggregate by sales per day, reset inddex and then merge\nbrand_dummies_agg = brand_dummies_train.groupby('Date').sum() \nbrand_dummies_agg_t = brand_dummies_test.groupby('Date').sum() \nbrand_dummies_agg = brand_dummies_agg.reset_index()\nbrand_dummies_agg_t = brand_dummies_agg_t.reset_index()\n\nbrand_dummies_agg.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:53.024440Z","iopub.execute_input":"2023-11-30T23:10:53.025624Z","iopub.status.idle":"2023-11-30T23:10:53.074979Z","shell.execute_reply.started":"2023-11-30T23:10:53.025572Z","shell.execute_reply":"2023-11-30T23:10:53.073910Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"brand_dummies_agg_t.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:53.076490Z","iopub.execute_input":"2023-11-30T23:10:53.077599Z","iopub.status.idle":"2023-11-30T23:10:53.092869Z","shell.execute_reply.started":"2023-11-30T23:10:53.077558Z","shell.execute_reply":"2023-11-30T23:10:53.091134Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggsale_train= aggsale_train.merge(brand_dummies_agg, on='Date', how='left')\naggsale_test= aggsale_test.merge(brand_dummies_agg_t, on='Date', how='left')\naggsale_train.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:53.095070Z","iopub.execute_input":"2023-11-30T23:10:53.096096Z","iopub.status.idle":"2023-11-30T23:10:53.143387Z","shell.execute_reply.started":"2023-11-30T23:10:53.096042Z","shell.execute_reply":"2023-11-30T23:10:53.141949Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggsale_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:53.145113Z","iopub.execute_input":"2023-11-30T23:10:53.146290Z","iopub.status.idle":"2023-11-30T23:10:53.167808Z","shell.execute_reply.started":"2023-11-30T23:10:53.146240Z","shell.execute_reply":"2023-11-30T23:10:53.166263Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train['Description'].nunique()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:53.174212Z","iopub.execute_input":"2023-11-30T23:10:53.175384Z","iopub.status.idle":"2023-11-30T23:10:53.283156Z","shell.execute_reply.started":"2023-11-30T23:10:53.175310Z","shell.execute_reply":"2023-11-30T23:10:53.281686Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:53.284916Z","iopub.execute_input":"2023-11-30T23:10:53.285335Z","iopub.status.idle":"2023-11-30T23:10:53.307562Z","shell.execute_reply.started":"2023-11-30T23:10:53.285277Z","shell.execute_reply":"2023-11-30T23:10:53.306405Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndesc_sales_sum = train.groupby('Description')['Sales'].sum()\ntop_desc = desc_sales_sum.sort_values(ascending=False).head(100)\n\nprint(top_desc)\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:53.308942Z","iopub.execute_input":"2023-11-30T23:10:53.309311Z","iopub.status.idle":"2023-11-30T23:10:53.526371Z","shell.execute_reply.started":"2023-11-30T23:10:53.309281Z","shell.execute_reply":"2023-11-30T23:10:53.524920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n#Convert the series to a DataFrame\ntop_desc_df = top_desc.reset_index()\ntop_desc_df.columns = ['Description', 'Sales']\n\n\ndef combine_specific_descriptions(desc):\n    if re.search(r'No\\. 4(\\D|$)', desc):\n        return 'No. 4'\n    elif re.search(r'No\\. 8(\\D|$)', desc):\n        return 'No. 8'\n    elif re.search(r'No\\. 25(\\D|$)', desc):\n        return 'No. 25'\n    elif re.search(r'No\\. 12(\\D|$)', desc):\n        return 'No. 12'\n    elif re.search(r'No\\. 70(\\D|$)', desc):\n        return 'No. 70'\n    elif re.search(r'No\\. 9(\\D|$)', desc):\n        return 'No. 9'\n    elif re.search(r'No\\. 52(\\D|$)', desc):\n        return 'No. 52'\n    elif re.search(r'No\\. 71(\\D|$)', desc):\n        return 'No. 71'\n    elif re.search(r'No\\. 88(\\D|$)', desc):\n        return 'No. 88'\n    elif re.search(r'No\\. 40(\\D|$)', desc):\n        return 'No. 40'\n    elif re.search(r'No\\. 18(\\D|$)', desc):\n        return 'No. 18'\n    elif re.search(r'No\\. 1(\\D|$)', desc):\n        return 'No. 1'\n    elif re.search(r'No\\. 31(\\D|$)', desc):\n        return 'No. 31'\n    elif re.search(r'No\\. 100(\\D|$)', desc):\n        return 'No. 100'\n    elif re.search(r'No\\. 67(\\D|$)', desc):\n        return 'No. 67'\n    elif re.search(r'No\\. 59(\\D|$)', desc):\n        return 'No. 59'\n    elif re.search(r'No\\. 72(\\D|$)', desc):\n        return 'No. 72'\n    elif re.search(r'No\\. 68(\\D|$)', desc):\n        return 'No. 68'\n    elif re.search(r'No\\. 64(\\D|$)', desc):\n        return 'No. 64'\n    elif re.search(r'No\\. 83(\\D|$)', desc):\n        return 'No. 83'\n    elif re.search(r'No\\. 53(\\D|$)', desc):\n        return 'No. 53'\n    elif re.search(r'No\\. 76(\\D|$)', desc):\n        return 'No. 76'\n    elif re.search(r'No\\. 90(\\D|$)', desc):\n        return 'No. 90'\n    else:\n        return desc\n\n# Apply this function to the 'Description' column\ntop_desc_df['Description'] = top_desc_df['Description'].apply(combine_specific_descriptions)\n\n# Group by the new description and sum the sales\ncombined_desc_sales = top_desc_df.groupby('Description')['Sales'].sum()\n\n# Sort the values if needed\ncombined_desc_sales = combined_desc_sales.sort_values(ascending=False)\n\ncombined_desc_sales.head(50)\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:53.527831Z","iopub.execute_input":"2023-11-30T23:10:53.528216Z","iopub.status.idle":"2023-11-30T23:10:53.562226Z","shell.execute_reply.started":"2023-11-30T23:10:53.528186Z","shell.execute_reply":"2023-11-30T23:10:53.560905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_desc_saleslim = combined_desc_sales.head(10)\nplt.figure(figsize=(8, 5))\nsns.barplot(x=combined_desc_saleslim.values, y=combined_desc_saleslim.index)\n\nplt.title('Top Ten Selling Items')\nplt.xlabel('Total Sales')\nplt.ylabel('Item')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:53.563710Z","iopub.execute_input":"2023-11-30T23:10:53.564112Z","iopub.status.idle":"2023-11-30T23:10:54.030020Z","shell.execute_reply.started":"2023-11-30T23:10:53.564082Z","shell.execute_reply":"2023-11-30T23:10:54.028886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"The difference between items is very small after the first few. Setting these up as features to see if they have an impact on the model. ","metadata":{}},{"cell_type":"code","source":"\ndesc_test = test.groupby('Description')['Sales'].sum()\ndesc_test = desc_test.sort_values(ascending=False).head(10)\n\nprint(desc_test)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:54.031630Z","iopub.execute_input":"2023-11-30T23:10:54.032312Z","iopub.status.idle":"2023-11-30T23:10:54.048110Z","shell.execute_reply.started":"2023-11-30T23:10:54.032275Z","shell.execute_reply":"2023-11-30T23:10:54.046754Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# combine the similar items\ndesc_test_df = desc_test.reset_index()\ndesc_test_df.columns = ['Description', 'Sales']\n\n\ndef combine_specific_descriptions(desc):\n    if re.search(r'No\\. 4(\\D|$)', desc):\n        return 'No. 4'\n    elif re.search(r'No\\. 8(\\D|$)', desc):\n        return 'No. 8'\n    elif re.search(r'No\\. 25(\\D|$)', desc):\n        return 'No. 25'\n    elif re.search(r'No\\. 12(\\D|$)', desc):\n        return 'No. 12'\n    elif re.search(r'No\\. 70(\\D|$)', desc):\n        return 'No. 70'\n    elif re.search(r'No\\. 9(\\D|$)', desc):\n        return 'No. 9'\n    elif re.search(r'No\\. 52(\\D|$)', desc):\n        return 'No. 52'\n    elif re.search(r'No\\. 71(\\D|$)', desc):\n        return 'No. 71'\n    elif re.search(r'No\\. 88(\\D|$)', desc):\n        return 'No. 88'\n    elif re.search(r'No\\. 40(\\D|$)', desc):\n        return 'No. 40'\n    elif re.search(r'No\\. 18(\\D|$)', desc):\n        return 'No. 18'\n    elif re.search(r'No\\. 1(\\D|$)', desc):\n        return 'No. 1'\n    elif re.search(r'No\\. 31(\\D|$)', desc):\n        return 'No. 31'\n    elif re.search(r'No\\. 100(\\D|$)', desc):\n        return 'No. 100'\n    elif re.search(r'No\\. 67(\\D|$)', desc):\n        return 'No. 67'\n    elif re.search(r'No\\. 59(\\D|$)', desc):\n        return 'No. 59'\n    elif re.search(r'No\\. 72(\\D|$)', desc):\n        return 'No. 72'\n    elif re.search(r'No\\. 68(\\D|$)', desc):\n        return 'No. 68'\n    elif re.search(r'No\\. 64(\\D|$)', desc):\n        return 'No. 64'\n    elif re.search(r'No\\. 83(\\D|$)', desc):\n        return 'No. 83'\n    elif re.search(r'No\\. 53(\\D|$)', desc):\n        return 'No. 53'\n    elif re.search(r'No\\. 76(\\D|$)', desc):\n        return 'No. 76'\n    elif re.search(r'No\\. 90(\\D|$)', desc):\n        return 'No. 90'\n    else:\n        return desc\n\n\ndesc_test_df['Description'] = desc_test_df['Description'].apply(combine_specific_descriptions)\n\n# Group by the new description and sum the sales\ncombined_desc_sales = desc_test_df.groupby('Description')['Sales'].sum()\n\n# Sort the values if needed\ncombined_desc_salestest = combined_desc_sales.sort_values(ascending=False)\n\ncombined_desc_salestest.head(10)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:54.050487Z","iopub.execute_input":"2023-11-30T23:10:54.051380Z","iopub.status.idle":"2023-11-30T23:10:54.085496Z","shell.execute_reply.started":"2023-11-30T23:10:54.051337Z","shell.execute_reply":"2023-11-30T23:10:54.084101Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_desc_salestest=combined_desc_salestest.head(10)\n\nset1 = set(combined_desc_saleslim.index)\nset2 = set(combined_desc_salestest.index)\n\ncommon_items = set1.intersection(set2)\ncommon_items_list = list(common_items)\nprint(common_items_list)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:10:54.087077Z","iopub.execute_input":"2023-11-30T23:10:54.087522Z","iopub.status.idle":"2023-11-30T23:10:54.095252Z","shell.execute_reply.started":"2023-11-30T23:10:54.087488Z","shell.execute_reply":"2023-11-30T23:10:54.093933Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"These are the brands in common in the top ten for the training and test sets. \n","metadata":{}},{"cell_type":"code","source":"\ncommon_items_list.append('Shipping')\ndef categorize_item(item):\n    item_str = str(item)\n    for common_item in common_items_list:\n        if common_item in item_str:\n            return common_item\n    return 'Other'\n\ntrain_at['Common_Item'] = train_at['Description'].apply(categorize_item)\ntest_at['Common_Item'] = test_at['Description'].apply(categorize_item)\n\n\n# Create dummy variables\nitem_dummies_train = pd.get_dummies(train_at['Common_Item']).astype(int)\nitem_dummies_test = pd.get_dummies(test_at['Common_Item']).astype(int)\n\n# Checking the result\nitem_dummies_train.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:00.248141Z","iopub.execute_input":"2023-11-30T23:11:00.248618Z","iopub.status.idle":"2023-11-30T23:11:01.130132Z","shell.execute_reply.started":"2023-11-30T23:11:00.248579Z","shell.execute_reply":"2023-11-30T23:11:01.128802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"item_dummies_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:01.132078Z","iopub.execute_input":"2023-11-30T23:11:01.132453Z","iopub.status.idle":"2023-11-30T23:11:01.147002Z","shell.execute_reply.started":"2023-11-30T23:11:01.132423Z","shell.execute_reply":"2023-11-30T23:11:01.145599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#shipping\ntrain_at['Common_Item'] = train_at['Description'].apply(categorize_item)\ntest_at['Common_Item'] = test_at['Description'].apply(categorize_item)\n\n\n# Create dummy variables\nitem_dummies_train = pd.get_dummies(train_at['Common_Item']).astype(int)\nitem_dummies_test = pd.get_dummies(test_at['Common_Item']).astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:01.148796Z","iopub.execute_input":"2023-11-30T23:11:01.149855Z","iopub.status.idle":"2023-11-30T23:11:02.022635Z","shell.execute_reply.started":"2023-11-30T23:11:01.149809Z","shell.execute_reply":"2023-11-30T23:11:02.021224Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"item_dummies_train = item_dummies_train.drop(['Other'], axis =1)\nitem_dummies_test = item_dummies_test.drop(['Other'], axis =1)\nitem_dummies_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:02.025253Z","iopub.execute_input":"2023-11-30T23:11:02.025675Z","iopub.status.idle":"2023-11-30T23:11:02.061972Z","shell.execute_reply.started":"2023-11-30T23:11:02.025642Z","shell.execute_reply":"2023-11-30T23:11:02.060989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"item_dummies_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:02.063248Z","iopub.execute_input":"2023-11-30T23:11:02.064343Z","iopub.status.idle":"2023-11-30T23:11:02.077910Z","shell.execute_reply.started":"2023-11-30T23:11:02.064304Z","shell.execute_reply":"2023-11-30T23:11:02.076193Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"item_dummies_train_agg = item_dummies_train.groupby('Date').sum()\nitem_dummies_test_agg = item_dummies_test.groupby('Date').sum()\nitem_dummies_train_agg = item_dummies_train_agg.reset_index()\nitem_dummies_test_agg = item_dummies_test_agg.reset_index()\nitem_dummies_train_agg.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:02.364559Z","iopub.execute_input":"2023-11-30T23:11:02.365681Z","iopub.status.idle":"2023-11-30T23:11:02.407017Z","shell.execute_reply.started":"2023-11-30T23:11:02.365639Z","shell.execute_reply":"2023-11-30T23:11:02.405672Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"item_dummies_test_agg.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:02.792565Z","iopub.execute_input":"2023-11-30T23:11:02.793148Z","iopub.status.idle":"2023-11-30T23:11:02.807178Z","shell.execute_reply.started":"2023-11-30T23:11:02.793103Z","shell.execute_reply":"2023-11-30T23:11:02.806026Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggsale_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:03.243511Z","iopub.execute_input":"2023-11-30T23:11:03.244865Z","iopub.status.idle":"2023-11-30T23:11:03.264223Z","shell.execute_reply.started":"2023-11-30T23:11:03.244818Z","shell.execute_reply":"2023-11-30T23:11:03.263084Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggsale_train = aggsale_train.merge(item_dummies_train_agg, on='Date', how='left')\naggsale_test = aggsale_test.merge(item_dummies_test_agg, on='Date', how='left')\naggsale_train.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:03.778845Z","iopub.execute_input":"2023-11-30T23:11:03.779288Z","iopub.status.idle":"2023-11-30T23:11:03.825638Z","shell.execute_reply.started":"2023-11-30T23:11:03.779255Z","shell.execute_reply":"2023-11-30T23:11:03.824391Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggsale_test.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:04.496476Z","iopub.execute_input":"2023-11-30T23:11:04.496963Z","iopub.status.idle":"2023-11-30T23:11:04.522375Z","shell.execute_reply.started":"2023-11-30T23:11:04.496926Z","shell.execute_reply":"2023-11-30T23:11:04.520996Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggsale_train.set_index('Date', inplace=True)\naggregated_train = aggsale_train.groupby('Date').sum()\naggsale_test.set_index('Date', inplace=True)\naggregated_test = aggsale_test.groupby('Date').sum()\n\n# Check the result\naggregated_test.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:05.090279Z","iopub.execute_input":"2023-11-30T23:11:05.090745Z","iopub.status.idle":"2023-11-30T23:11:05.121163Z","shell.execute_reply.started":"2023-11-30T23:11:05.090699Z","shell.execute_reply":"2023-11-30T23:11:05.119812Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggsale_train = aggsale_train.asfreq('D')\naggsale_test = aggsale_test.asfreq('D')\n\n# Fill NaN values with 0\naggsale_train.fillna(0, inplace=True)\naggsale_test.fillna(0, inplace=True)\naggsale_train.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:05.616687Z","iopub.execute_input":"2023-11-30T23:11:05.617250Z","iopub.status.idle":"2023-11-30T23:11:05.631701Z","shell.execute_reply.started":"2023-11-30T23:11:05.617210Z","shell.execute_reply":"2023-11-30T23:11:05.630868Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggsale_test.isna().sum()","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:06.118504Z","iopub.execute_input":"2023-11-30T23:11:06.119438Z","iopub.status.idle":"2023-11-30T23:11:06.131463Z","shell.execute_reply.started":"2023-11-30T23:11:06.119392Z","shell.execute_reply":"2023-11-30T23:11:06.130007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = aggsale_train.copy()\n\n# Applying log transformation to the 'Sales' column\ny_log = np.log1p(y['Sales'])\n\nfourier = CalendarFourier(freq='M', order=4)\nfourier_annual = CalendarFourier(freq='A', order=4)#add weekly too, only has monthly, weird\nfourier_weekly = CalendarFourier(freq='W', order=4)\nfourier_quarterly = CalendarFourier(freq='Q', order=4)# Quarterly Fourier\n# Bimonthly Fourier\nfourier_bimonthly = CalendarFourier(freq='2M', order=4)\ndp = DeterministicProcess(\n    index=y.index,\n    constant=True,\n    order=1,\n    seasonal=True,\n    additional_terms=[fourier,fourier_weekly,fourier_annual,fourier_quarterly, fourier_bimonthly],\n    drop=True,\n)\nX = dp.in_sample()\n\n\nX['Xmas25'] = ((X.index.month == 12) & (X.index.day == 25)).astype(int)\nX['Xmas24'] = ((X.index.month == 12) & (X.index.day == 24)).astype(int)\nX['Xmas23'] = ((X.index.month == 12) & (X.index.day == 23)).astype(int)\nX['Xmas22'] = ((X.index.month == 12) & (X.index.day == 22)).astype(int)\nX['Xmas21'] = ((X.index.month == 12) & (X.index.day == 21)).astype(int)\nX['Xmas20'] = ((X.index.month == 12) & (X.index.day == 20)).astype(int)\nX['Xmas18'] = ((X.index.month == 12) & (X.index.day == 18)).astype(int)\nX['Xmas14'] = ((X.index.month == 12) & (X.index.day == 14)).astype(int)\nX['Store_closed'] = aggsale_train['Store_closed']\n\nX['Cost of Goods'] = aggsale_train['Cost of Goods']\n#X['Inventory'] = aggsale_train['Inventory']\nX['Logistics'] = aggsale_train['Logistics']\nX['Revenue Accessories'] = aggsale_train['Revenue Accessories']\nX['Revenue candles'] = aggsale_train['Revenue candles']\nX['Revenue Workshop'] = aggsale_train['Revenue Workshop']\nX['nan'] = aggsale_train['nan']\n\nX['Cozy Corner'] = aggsale_train['Cozy Corner']\nX['Petalume'] = aggsale_train['Petalume']\nX['Bliss Bungalow'] = aggsale_train['Bliss Bungalow']\nX['AromaGarden'] = aggsale_train['AromaGarden']\nX['Hearth Harbor'] = aggsale_train['Hearth Harbor']\nX['Meadow Mingle'] = aggsale_train['Meadow Mingle']\n\n#X['No. 8'] = aggsale_train['No. 8']\n#X['AromaGarden Gardenia candle'] = aggsale_train['AromaGarden Gardenia candle']\n#X['No. 31'] = aggsale_train['No. 31']\n#X['No. 25'] = aggsale_train['No. 25']\nX['Shipping'] = aggsale_train['Shipping']\n\nmodel = LinearRegression(fit_intercept=False)\n#model.fit(X, y)\nmodel.fit(X, y_log)\n\ny_pred_log = model.predict(X)\ny_pred_insample = np.expm1(y_pred_log)  # Inverse of log1p\n\n# Creating a DataFrame for the predicted values\ny_pred_insample= pd.DataFrame(y_pred_insample, index=X.index, columns=['Sales'])\n\n\n#model.fit(X, y['Sales'])\n#y_pred_insample = pd.DataFrame(model.predict(X), index=X.index, columns=['Sales'])\n#y_pred = pd.DataFrame(model.predict(X), index=X.index, columns=y.columns)","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:06.563229Z","iopub.execute_input":"2023-11-30T23:11:06.563696Z","iopub.status.idle":"2023-11-30T23:11:06.746126Z","shell.execute_reply.started":"2023-11-30T23:11:06.563661Z","shell.execute_reply":"2023-11-30T23:11:06.744507Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\ndef rmsle(y_true, y_pred):\n    \n    # Ensure the arrays are numpy arrays\n    y_true = np.array(y_true)\n    y_pred = np.array(y_pred)\n    \n    # Compute the squared logarithmic error\n    error = (np.log(y_pred + 1) - np.log(y_true + 1)) ** 2\n    \n    # Return the square root of the mean of the squared logarithmic error\n    return np.sqrt(np.mean(error))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:06.983753Z","iopub.execute_input":"2023-11-30T23:11:06.984755Z","iopub.status.idle":"2023-11-30T23:11:06.991234Z","shell.execute_reply.started":"2023-11-30T23:11:06.984701Z","shell.execute_reply":"2023-11-30T23:11:06.990159Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# there are negative predictions in the data, for now clip them to 0 or low pos near 0 to make the calc work\n# Clip negative predictions to 0\n\n# Now, compute RMSLE\nin_sample_rmsle = rmsle(y['Sales'], y_pred_insample['Sales'].clip(lower=0))\nprint(f\"In-sample RMSLE: {in_sample_rmsle}\")\n\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:07.413845Z","iopub.execute_input":"2023-11-30T23:11:07.415302Z","iopub.status.idle":"2023-11-30T23:11:07.423024Z","shell.execute_reply.started":"2023-11-30T23:11:07.415262Z","shell.execute_reply":"2023-11-30T23:11:07.422141Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creates feature set for the forecast data (out_of_sample) \n\nX_test = dp.out_of_sample(steps=15)\nX_test['Xmas25'] = ((X_test.index.month == 12) & (X_test.index.day == 25)).astype(int)\nX_test['Xmas24'] = ((X_test.index.month == 12) & (X_test.index.day == 24)).astype(int)\nX_test['Xmas23'] = ((X_test.index.month == 12) & (X_test.index.day == 23)).astype(int)\nX_test['Xmas22'] = ((X_test.index.month == 12) & (X_test.index.day == 22)).astype(int)\nX_test['Xmas21'] = ((X_test.index.month == 12) & (X_test.index.day == 21)).astype(int)\nX_test['Xmas20'] = ((X_test.index.month == 12) & (X_test.index.day == 20)).astype(int)\nX_test['Xmas18'] = ((X_test.index.month == 12) & (X_test.index.day == 18)).astype(int)\nX_test['Xmas14'] = ((X_test.index.month == 12) & (X_test.index.day == 14)).astype(int)\nX_test['Store_closed'] = aggsale_test['Store_closed']\n\nX_test['Cost of Goods'] = aggsale_test['Cost of Goods']\n#X_test['Inventory'] = aggsale_test['Inventory']\nX_test['Logistics'] = aggsale_test['Logistics']\nX_test['Revenue Accessories'] = aggsale_test['Revenue Accessories']\nX_test['Revenue candles'] = aggsale_test['Revenue candles']\nX_test['Revenue Workshop'] = aggsale_test['Revenue Workshop']\nX_test['nan'] = aggsale_test['nan']\n\nX_test['Cozy Corner'] = aggsale_test['Cozy Corner']\nX_test['Petalume'] = aggsale_test['Petalume']\nX_test['Bliss Bungalow'] = aggsale_test['Bliss Bungalow']\nX_test['AromaGarden'] = aggsale_test['AromaGarden']\nX_test['Hearth Harbor'] = aggsale_test['Hearth Harbor']\nX_test['Meadow Mingle'] = aggsale_test['Meadow Mingle']\n\n#X_test['No. 8'] = aggsale_test['No. 8']\n#X_test['AromaGarden Gardenia candle'] = aggsale_test['AromaGarden Gardenia candle']\n#X_test['No. 31'] = aggsale_test['No. 31']\n#X_test['No. 25'] = aggsale_test['No. 25']\nX_test['Shipping'] = aggsale_test['Shipping']\n\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:07.793935Z","iopub.execute_input":"2023-11-30T23:11:07.794616Z","iopub.status.idle":"2023-11-30T23:11:07.838583Z","shell.execute_reply.started":"2023-11-30T23:11:07.794583Z","shell.execute_reply":"2023-11-30T23:11:07.837372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict using the model on the out-of-sample data\ny_pred_outsample_log = model.predict(X_test)\n\n\ny_pred_outsample = np.expm1(y_pred_outsample_log).flatten()  # Flatten if it's a 2D array with one column\ny_pred_outsample_df = pd.DataFrame(y_pred_outsample, index=X_test.index, columns=['Sales'])\n\nout_sample_rmsle = rmsle(aggsale_test['Sales'], y_pred_outsample_df['Sales'].clip(lower=0))\nprint(f\"Out-of-sample RMSLE: {out_sample_rmsle}\")\n#model = LinearRegression(fit_intercept=False)\n#model.fit(X, y_log)  .\n\n\n\n# Applying inverse log transformation to the predictions\n#y_pred_outsample = np.expm1(y_pred_outsample_log)\n\n# Creating a DataFrame for the predicted values\n#y_pred_outsample_df = pd.DataFrame(y_pred_outsample, index=X_test.index, columns=['Sales'])\n\n# Calculate RMSLE for Out-of-Sample Data\n# Make sure aggsale_test['Sales'] is the actual sales data corresponding to the out-of-sample period\n#out_sample_rmsle = rmsle(aggsale_test['Sales'], y_pred_outsample_df['Sales'].clip(lower=0))\n#print(f\"Out-of-sample RMSLE: {out_sample_rmsle}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:08.243577Z","iopub.execute_input":"2023-11-30T23:11:08.244951Z","iopub.status.idle":"2023-11-30T23:11:08.258829Z","shell.execute_reply.started":"2023-11-30T23:11:08.244910Z","shell.execute_reply":"2023-11-30T23:11:08.257611Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"##model = LinearRegression(fit_intercept=False)\n##model.fit(X, y['Sales'])\n#y_pred_outsample = pd.DataFrame(model.predict(X_test), index=X_test.index, columns=['Sales'])\n\n\n\n# Creating a DataFrame for the predicted values\n#y_pred_outsample = pd.DataFrame(y_pred_outsample, index=X_test.index, columns=['Sales'])\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:08.659108Z","iopub.execute_input":"2023-11-30T23:11:08.659582Z","iopub.status.idle":"2023-11-30T23:11:08.664207Z","shell.execute_reply.started":"2023-11-30T23:11:08.659546Z","shell.execute_reply":"2023-11-30T23:11:08.663182Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#out_sample_rmsle = rmsle(aggsale_test['Sales'], y_pred_outsample['Sales'])\n#print(f\"Out-of-sample RMSLE: {out_sample_rmsle}\")","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:09.117490Z","iopub.execute_input":"2023-11-30T23:11:09.118841Z","iopub.status.idle":"2023-11-30T23:11:09.124311Z","shell.execute_reply.started":"2023-11-30T23:11:09.118784Z","shell.execute_reply":"2023-11-30T23:11:09.122621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\nplt.plot(y['Sales'], label='Training Data', color='blue')\nplt.plot(y_pred_insample['Sales'], label='Model', color='orange')\nplt.title('In-Sample Sales Prediction')\nplt.xlabel('Date')\nplt.ylabel('Sales')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:09.601462Z","iopub.execute_input":"2023-11-30T23:11:09.601979Z","iopub.status.idle":"2023-11-30T23:11:10.261393Z","shell.execute_reply.started":"2023-11-30T23:11:09.601940Z","shell.execute_reply":"2023-11-30T23:11:10.260121Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(10, 6))\n\n# Plotting the predicted out-of-sample sales\nplt.plot(y_pred_outsample_df.index, y_pred_outsample_df['Sales'], label='Prediction', color='green')\n\n# Plotting the actual out-of-sample sales\nplt.plot(aggsale_test.index, aggsale_test['Sales'], label='Test data', color='red')\n\nplt.title('Sales Prediction')\nplt.xlabel('Date')\nplt.ylabel('Sales')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:10.696806Z","iopub.execute_input":"2023-11-30T23:11:10.697294Z","iopub.status.idle":"2023-11-30T23:11:11.241670Z","shell.execute_reply.started":"2023-11-30T23:11:10.697257Z","shell.execute_reply":"2023-11-30T23:11:11.240355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(12, 6))\nplt.plot(y['Sales'], label='Training data', color='blue')\n#plt.plot(aggsale_test['Sales'], label='Test data', color='red')\n\nplt.plot(y_pred_insample['Sales'], label='Model', color='orange')\n#plt.plot(y_pred_outsample['Sales'], label='Prediction', color='green')\nplt.plot(y_pred_outsample_df.index, y_pred_outsample_df['Sales'], label='Prediction', color='green')\n\n# Plotting the actual out-of-sample sales\nplt.plot(aggsale_test.index, aggsale_test['Sales'], label='Test data', color='red')\n\n\n\nplt.title('Sales Model and Prediction')\nplt.xlabel('Date')\nplt.ylabel('Sales')\nplt.legend()\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:11.248864Z","iopub.execute_input":"2023-11-30T23:11:11.249395Z","iopub.status.idle":"2023-11-30T23:11:11.928218Z","shell.execute_reply.started":"2023-11-30T23:11:11.249358Z","shell.execute_reply":"2023-11-30T23:11:11.927187Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = {\n    'Model Features': ['Dec 20-25', \n                       'Dec 14,18,20-25',\n                       'Dec 14,18,20-25, Store Closed',\n                       'Dec 14,18,20-25, Store Closed,Tday, 4th',\n                       'Dec 14,18,20-25, Store Closed, COGS',\n                       'Dec 14,18,20-25, Store Closed, All Account Type',\n                       'Dec 14,18,20-25, Store Closed, Account Type, Brands',\n                       'Dec 14,18,20-25, Store Closed, Account Type, Product Types',\n                       'Log Transformation Dec14, 18,20-25, Store Closed, Account Type'],\n    'RSMLE training data': ['1.44', '1.43','0.90','0.93','0.58','0.58','0.58','0.58','0.30'],\n    'RSMLE prediction': ['0.59', '0.57','0.55','0.55','0.18','0.13','0.13','0.13','0.24']\n}\nRSMLE_model = pd.DataFrame(data)\n\n\nRSMLE_model","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:11.929848Z","iopub.execute_input":"2023-11-30T23:11:11.931199Z","iopub.status.idle":"2023-11-30T23:11:11.948891Z","shell.execute_reply.started":"2023-11-30T23:11:11.931160Z","shell.execute_reply":"2023-11-30T23:11:11.947409Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"aggsale_train.head()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:12.346124Z","iopub.execute_input":"2023-11-30T23:11:12.346857Z","iopub.status.idle":"2023-11-30T23:11:12.382645Z","shell.execute_reply.started":"2023-11-30T23:11:12.346811Z","shell.execute_reply":"2023-11-30T23:11:12.381180Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Filter training data\nX_train_cozy_corner = X[X['Cozy Corner'] > 0]\ny_train_cozy_corner = y[X['Cozy Corner'] >0 ]\n\n# Filter the test data\nX_test_cozy_corner = X_test[X_test['Cozy Corner'] >0]\ny_test_cozy_corner = aggsale_test[X_test['Cozy Corner'] >0]['Sales']  # Assuming 'Sales' is your target variable\n\n# Ensure y_test_cozy_corner is a 1D array\ny_test_cozy_corner = y_test_cozy_corner.values.ravel()  # Converts to numpy array and flattens it\n\nmodel = LinearRegression(fit_intercept=False)\nmodel.fit(X_train_cozy_corner, y_train_cozy_corner)\n\n# Predict and select the correct column \ny_pred_cozy_corner = model.predict(X_test_cozy_corner)[:, 0]  \n# Calculate RMSLE\nrmsle_cozy_corner = rmsle(y_test_cozy_corner, y_pred_cozy_corner)\nprint(f\"RMSLE for 'Cozy Corner': {rmsle_cozy_corner}\")\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:12.913976Z","iopub.execute_input":"2023-11-30T23:11:12.914466Z","iopub.status.idle":"2023-11-30T23:11:12.953804Z","shell.execute_reply.started":"2023-11-30T23:11:12.914431Z","shell.execute_reply":"2023-11-30T23:11:12.952092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n\ndata = {\n    'Features': ['All Sales', 'Petalume','Cozy Corner','Candles','Accessories','Workshops','AromaGarden Gardenia candle','Candle Scent No. 8'],\n    'RSMLE': ['0.13', '0.13','0.17','0.13','0.13','0.13','0.06','0.13']\n}\nRSMLE_per_feature = pd.DataFrame(data)\n\n\nRSMLE_per_feature\n#print(RSMLE_per_feature.to_string(index=False))\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-30T23:11:13.482759Z","iopub.execute_input":"2023-11-30T23:11:13.483211Z","iopub.status.idle":"2023-11-30T23:11:13.498454Z","shell.execute_reply.started":"2023-11-30T23:11:13.483179Z","shell.execute_reply":"2023-11-30T23:11:13.497482Z"},"trusted":true},"execution_count":null,"outputs":[]}]}